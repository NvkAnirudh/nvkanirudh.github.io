<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Education</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Venkata Krishna Anirudh</strong> Nuti</a>
									<ul class="icons">
										<li><a href="https://www.linkedin.com/in/nvkanirudh/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://github.com/NvkAnirudh" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
										<li><a href="https://www.instagram.com/anirudhnuti/" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="https://medium.com/@nuti.krish4" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>                            
									<header class="main">
										<h1>Projects</h1>					
									</header>
									
									<p>My portfolio includes seven projects on different topics focusing on Machine Learning, Computer Vision, Data Analysis, Statistics, ETL, and Cloud Deployment (AWS). 
										Projects can be viewed by category below.</p>
									<p>This page features projects from following topics:</p>
									<ul>
										<li><a href="#project_1">Computer Vision</a></li>
										<li><a href="#project_2">Diffusion Models</a></li>
										<li><a href="#project_3">Data Analysis</a></li>
										<li><a href="#project_4">Statistical Analysis</a></li>
										<li><a href="#project_5">Extract, Transform, and Load</a></li>
									</ul>

									<p>
										<a id="project_1"></a>
									</p>

									<div>
										<h1>Computer Vision</h1>
									</div>

									<div class="card">

										<h2><b> Smile Detection using Deep Learning </b></h2>
									  
										<img src="images/smile.jpeg" alt="Notebook" style="width:100%">
									  
										<h3> Highlights </h3>
										<ul>
										<li> Developed a smile detection classifier using several state-of-the-art CNN architectures using TensorFlow. </li>
										<li> The architectures include ResNet50, Xception, ResNet152V2, VGG16, InceptionResNetv2, and LeNet5. </li>
										<li> Achieved highest accuracy of 89% with Xception architecture. </li>
										</ul>
									  
										<p> <b>Tags:</b> Python, Computer Vision, TensorFlow, Deep Learning, Convolutional Neural Networks </p>
									  
										<span id="dots1" style="display: inline;"><p></p></span>
										<span id="more1" style="display: inline;">
										<h3> Summary </h3>
										<p> Developed a smile detection classifier using TensorFlow, a popular deep learning framework. The classifier was built using several state-of-the-art convolutional neural network (CNN) architectures, including ResNet50, Xception, ResNet152V2, VGG16, InceptionResNetv2, and LeNet5. These architectures are widely used in computer vision tasks and have been shown to perform well on a variety of datasets. </p>
										<p> Reported that the Xception architecture achieved the highest accuracy among all the models, with an accuracy of 89%. This result suggests that Xception may be a good choice for smile detection tasks, at least for the dataset used in this study. The use of multiple architectures and careful evaluation of their performance can help researchers choose the best model for their specific task and data.</p>
										<h5> Below are the statistics calculated with Xception architecture:  </h5>
										<img src="images/xception.png" alt="Notebook" style="width:100%">
										</span>
									  
										<button class="btn" onclick="window.open('https://github.com/NvkAnirudh/Smile-Detection-using-CNN')" type="button">GitHub repo</button>
									
									  
									</div>

									<hr class="major" />

									<div class="card">

										<h2><b> Detection of COVID-19 in X-Ray images </b></h2>
									  
										<img src="images/chestx-ray.png" alt="Notebook" style="width:100%">
									  
										<h3> Highlights </h3>
										<ul>
										<li> Built a binary classification model using chest X-Ray images and VGG-16 convolutional neural network architecture pre-trained on ImageNet.</li>
										<li> New fully-connected layer was added to the pre-trained network to classify images as either normal or COVID-affected.</li>										
										<li> Model was trained and achieved an accuracy of 93%.</li>
										</ul>
									  
										<p> <b>Tags:</b> Python, Computer Vision, TensorFlow, Deep Learning, Convolutional Neural Networks </p>
									  
										<span id="dots1" style="display: inline;"><p></p></span>
										<span id="more1" style="display: inline;">
										<h3> Summary </h3>
										<p> In recent years, deep learning has shown promising results in medical image analysis, including detecting COVID-19 from chest X-rays. One popular approach is to use pre-trained convolutional neural network (CNN) models, such as VGG-16, ResNet, or DenseNet, and fine-tune them on COVID-19 chest X-ray datasets. The fine-tuning process involves removing the original classification layer and adding a new one to adapt the model to the specific COVID-19 detection task.</p>
										<p> Besides using pre-trained models, researchers have also developed specialized architectures for COVID-19 detection. For example, COVID-Net is a CNN model specifically designed for COVID-19 detection from chest X-rays. COVID-Net uses a series of convolutional and pooling layers followed by several fully-connected layers to classify chest X-rays as normal, pneumonia, or COVID-19.</p>
										<p> The goal of the project is to develop a machine learning model that can accurately and quickly detect COVID-19 infection from chest X-ray images. By achieving an accuracy of 93%, the model shows promise as a potential tool for COVID-19 screening and diagnosis.</p>
										</span>
									  
										<button class="btn" onclick="window.open('https://github.com/NvkAnirudh/Covid-19-XRay-Detection')" type="button">GitHub repo</button>
									
									  
									</div>
									

									<hr class="major" />	
									
									<p>
										<a id="project_2"></a>
									</p>

									<div>
										<h1>Diffusion Models</h1>
									</div>

									<div class="card">

										<h2><b> Image Generation of Butterflies using Diffusion Models </b></h2>
									  
										<img src="images/butterflies.png" alt="Notebook" style="width:100%">
									  
										<h3> Highlights </h3>
										<ul>
										<li> Trained a diffusion model using Hugging Face's diffusers library to generate visually impressive butterfly images.</li>
										<li> Used a noise scheduler to add noise to 1000 high-quality butterfly images and trained a UNet architecture for denoising.</li>
										<li> Employed the backward denoising process, optimizing the model parameters using AdamW optimizer and minimizing the mean squared error (MSE) loss function.</li>
										</ul>
									  
										<p> <b>Tags:</b> Python, Hugging Face, PyTorch, Deep Learning</p>
									  
										<span id="dots1" style="display: inline;"><p></p></span>
										<span id="more1" style="display: inline;">
										<h3> Summary </h3>
										<p> DDPM (Denoising Diffusion Probabilistic Models) is a type of generative model that can learn to generate realistic images by estimating the probability distribution of the data. DDPMs use a diffusion process to transform a random noise signal into an image that is close to the target distribution. In the diffusion process, noise is gradually added to the signal, and the signal is then denoised using a neural network. By iteratively adding noise and denoising, the model can learn to generate high-quality images that match the target distribution.</p>
										<p> Stable diffusion is a modification of the diffusion process used in DDPMs to improve their stability and performance. In stable diffusion, the amount of noise added to the signal is adaptively adjusted at each step to ensure that the signal remains close to the target distribution. This adaptation is done by monitoring the signal's gradient and scaling the noise accordingly. Stable diffusion can help avoid numerical instability and ensure that the diffusion process converges to the target distribution efficiently.</p>
										<p> In this project, a diffusion model was trained using Hugging Face's diffusers library to generate stunning butterfly images. To improve the quality of the images generated by the diffusion model, a UNet architecture was trained for denoising using a noise scheduler that added noise to 1000 clean butterfly images. The backward denoising process was implemented using the AdamW optimizer and the mean squared error (MSE) loss function to update the model parameters. Overall, this approach allowed for the generation of visually impressive butterfly images with improved quality and clarity.
										</p>
										<h5>Below is how the noise is added to a clean butterfly image:</h5>
										<img src="images/noisy_butterfly.png" alt="Notebook" style="width:100%">
										</span>
									  
										<button class="btn" onclick="window.open('https://github.com/NvkAnirudh/Diffusion-Models-Practice')" type="button">GitHub repo</button>
									
									  
									</div>

									<hr class="major" />

									<p>
										<a id="project_3"></a>
									</p>

									<div>
										<h1>Data Analysis</h1>
									</div>

									<div class="card">

										<h2><b> Financial Service Analysis using R, MongoDB, and AWS </b></h2>
									  
										<img src="images/mongodb-aws-logos.jpeg" alt="Notebook" style="width:100%">
									  
										<h3> Highlights </h3>
										<ul>
										<li> Worked on data analysis for financial services using MongoDB database containing three documents.</li>
										<li> Created a docker container to run MongoDB data analysis in R and deployed it on AWS EC2 instance using Jenkins
											pipeline for continuous integration and deployment of Docker images from GIT.</li>										
										</ul>
									  
										<p> <b>Tags:</b> R, NoSQL (MongoDB), Docker, Jenkins, AWS</p>
									  
										<span id="dots1" style="display: inline;"><p></p></span>
										<span id="more1" style="display: inline;">
										<h3> Summary </h3>
										<p> In this project, I worked on data analysis for financial services using a MongoDB database containing three documents. To analyze the data, I created a docker container to run MongoDB in R and deployed it on an AWS EC2 instance. To facilitate continuous integration and deployment of Docker images from Git, I set up a Jenkins pipeline. This approach allowed for efficient and streamlined data analysis and deployment, enabling the financial services company to make data-driven decisions and improve their business operations.</p>										
										</p>
										</span>
									  
										<button class="btn" onclick="window.open('https://github.com/NvkAnirudh/Financial-Services-Analysis-using-R-and-MongoDB')" type="button">GitHub repo</button>																		  
									</div>

									<hr class="major" />

									<div class="card">

										<h2><b> Google Data Analytics Case Study </b></h2>
									  
										<img src="images/google.jpeg" alt="Notebook" style="width:100%">
									  
										<h3> Highlights </h3>
										<ul>
										<li> This project was performed as part of Google Data Analytics Professional Certificate</li>
										<li> Performed real-world data analysis in R for a fictional company called Cyclistic.</li>										
										</ul>
									  
										<p> <b>Tags:</b> R, Data Analysis</p>
									  
										<span id="dots1" style="display: inline;"><p></p></span>
										<span id="more1" style="display: inline;">
										<h3> Summary </h3>
										<p> <b>Hypothetical Scenario:</b></p>
										<p>I am a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore, our team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, our team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve our recommendations, so they must be backed up with compelling data insights and professional data visualizations.</p>
										</p>
										</span>
									  
										<button class="btn" onclick="window.open('https://github.com/NvkAnirudh/Data_Analytics_CaseStudy_1')" type="button">GitHub repo</button>																		  
									</div>

									<hr class="major" />

									<p>
										<a id="project_4"></a>
									</p>

									<div>
										<h1>Statistical Analysis</h1>
									</div>

									<div class="card">

										<h2><b> Campus Recruitment Analysis </b></h2>
									  
										<img src="images/Methods-of-Statistical-Analysis.jpeg" alt="Notebook" style="width:100%">
									  
										<h3> Highlights </h3>
										<ul>
										<li> Conducted Multiple Linear Regression analysis to predict employment test percentage based on high school, secondary education, and degree percentages.</li>
										<li> Executed a one-way Analysis of Variance (ANOVA) to compare employment test percentage means between male and female groups.</li>
										</ul>
									  
										<p> <b>Tags:</b> R, Data Analysis</p>
									  
										<span id="dots1" style="display: inline;"><p></p></span>
										<span id="more1" style="display: inline;">
										<h3> Summary </h3>
										<p> <b>Hypothetical Scenario:</b></p>
										<p>I am a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore, our team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, our team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve our recommendations, so they must be backed up with compelling data insights and professional data visualizations.</p>
										</p>
										</span>
									  
										<button class="btn" onclick="window.open('https://github.com/NvkAnirudh/Campus_Recruitment')" type="button">GitHub repo</button>																		  
									</div>

									<hr class="major" />

									<p>
										<a id="project_5"></a>
									</p>

									<div>
										<h1>Extract, Transform, and Load (ETL)</h1>
									</div>

									<div class="card">

										<h2><b> ETL Using Apache Airflow and Kafka </b></h2>
									  
										<img src="images/ETL.jpeg" alt="Notebook" style="width:100%">
									  
										<h3> Highlights </h3>
										<ul>
										<li> Performed ETL on National Highway Toll data by building data pipelines using Apache Airflow’s DAGs (Directed Acyclic
											Graphs) and loaded the data into PostgreSQL.</li>
										<li> Implemented streaming data pipelines to load the data into SQL Server database using SQL Queries in SSMS and Apache Kafka.</li>
										</ul>
									  
										<p> <b>Tags:</b> R, Data Analysis</p>
									  
										<span id="dots1" style="display: inline;"><p></p></span>
										<span id="more1" style="display: inline;">
										<h3> Summary </h3>										
										<p>ETL stands for Extract, Transform, and Load, which is a process of integrating data from multiple sources, transforming it into a useful format, and then loading it into a target system for analysis. It is an essential process in data warehousing, business intelligence, and data analytics.</p>
										<p> The goal of this project is to perform ETL on National Highway Toll data by creating data pipelines using Apache Airflow's DAGs. I extracted data from the source, transformed it into a suitable format, and loaded it into PostgreSQL database for analysis.</p>
										<p> I, then, implemented streaming data pipelines to load data into SQL Server database using Apache Kafka. It means that I have built a continuous data processing system that can process and load data in real-time, enabling businesses to gain insights and take actions faster.</p>
										</p>
										</span>
									  
										<button class="btn" onclick="window.open('https://github.com/NvkAnirudh/ETL')" type="button">GitHub repo</button>																		  
									</div>

									<hr class="major" />
									<!-- <div class="switch-container">
										<label class="switch">
										  <input type="checkbox">
										  <span class="slider round"></span>
										</label>
									</div> -->
									  


								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">							

							<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="index.html">About</a></li>										
									<li><a href="experience.html">Experience</a></li>
									<li><a href="projects.html">Projects</a></li>
									<!-- <li>
										<span class="opener">Projects</span>
										<ul>
											<li><a href="cv.html">Computer Vision</a></li>
											<li><a href="#">Data Analysis</a></li>
											<li><a href="#">Databases</a></li>
											<li><a href="#">Diffusin Models</a></li>
										</ul>
									</li> -->
									<li><a href="certifications.html">Certifications</a></li>
									<!-- <li><a href="#">More Me!</a></li> -->
								</ul>
							</nav>

						<!-- Section -->
							<section>
								<header class="major">
									<h2>Get in touch</h2>
								</header>
								<p>Feel Free to get in touch with me through email id or phone mentioned below. You can also reach out to me through social media profiles attached on top of this page. Peace!</p>
								<ul class="contact">
									<li class="icon solid fa-envelope"><a href="#">nuti.krish4@gmail.com</a></li>
									<li class="icon solid fa-phone">(857) 919-1884</li>
									<li class="icon solid fa-home">Boston, MA</li>
								</ul>
							</section>

						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">&copy; Untitled. All rights reserved.</a>.</p>
							</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>